LoRA : Low rank adaptation of large langauge models.
QLoRA : LoRA 2.0 that is Quantized LoRA 
If we train all parameters then we say full parameter fine tuning.
We can also do specific task fine tuning and domain specific fine tuning.

Challenges of full parameter fine tuning :
1) To update all model weights
2) Hardware resource constraint - It is difficult to do downstream task that is model inferencing, model monitoring, GPU and RAM constraints.

What does LoRA do?
Instead of updating the weights, it track changes. Here we use technique of matrix decomposition based on a parameter called rank.
Here we decompose a bigger matrix of huge parameters into two smaller matrices of small parameters.

W0(pre trained weights) + delta W(tracked changed weights) = W0(pre trained weights) + BA where B is matrix 1 and A is matrix 2.
Although, there is a loss of precision but still upon multiplicating all decomposed matrices we get almost same number of parameters.

Increasing rank increases parameters but still parameters will be less then the pre trained or base model.
So it is preferred to use low ranks like 1, 2, 8

When to use high ranks?
When the model wants to learn the complex things.

In QLoRA, we do quantization along with decomposition.

Execution Steps :
Install some libraries like accelerate, peft(parameter efficient transfer learning), bitsandbytes(used for doing quantization), trl and Transformers.